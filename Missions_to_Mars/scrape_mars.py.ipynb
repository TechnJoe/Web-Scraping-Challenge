{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert jupyter notebook to python script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Executable Path & Initialize Chrome Browser\n",
    "executable_path = {'executable_path': 'C:/Webdrivers/chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape NASA Mars News\n",
    "def marsNews():\n",
    "    news_url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(news_url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    try:\n",
    "        article = soup.find(\"div\", class_='list_text')\n",
    "        news_title = article.find(\"div\", class_=\"content_title\").text\n",
    "        news_p = article.find(\"div\", class_ =\"article_teaser_body\").text\n",
    "        output = [news_title, news_p]\n",
    "    except AttributeError:\n",
    "        output = ['7 Things to Know About the NASA Rover About to Land on Mars', 'The Mars 2020 Perseverance rover, which has started its approach to the Red Planet, will help answer the next logical question in Mars exploration.']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape JPL Mars Space - Featured image.\n",
    "def marsImage():\n",
    "    image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(image_url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    image = soup.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "    featured_image_url = \"https://www.jpl.nasa.gov\" + image\n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape mars facts\n",
    "def marsFacts():\n",
    "    import pandas as pd\n",
    "    facts_url = \"https://space-facts.com/mars/\"\n",
    "    browser.visit(facts_url)\n",
    "    mars_data = pd.read_html(facts_url)\n",
    "    mars_data = pd.DataFrame(mars_data[0])\n",
    "    mars_data.columns = [\"Description\", \"Value\"]\n",
    "    mars_data = mars_data.set_index(\"Description\")\n",
    "    mars_facts = mars_data.to_html(index = True, header =True)\n",
    "    return mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape Mars Hemispheres\n",
    "def marsHem():\n",
    "    import time \n",
    "    hemispheres_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(hemispheres_url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    mars_hemisphere = []\n",
    "\n",
    "    products = soup.find(\"div\", class_ = \"result-list\" )\n",
    "    hemispheres = products.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "    for hemisphere in hemispheres:\n",
    "        title = hemisphere.find(\"h3\").text\n",
    "        title = title.replace(\"Enhanced\", \"\")\n",
    "        end_link = hemisphere.find(\"a\")[\"href\"]\n",
    "        image_link = \"https://astrogeology.usgs.gov/\" + end_link    \n",
    "        browser.visit(image_link)\n",
    "        html = browser.html\n",
    "        soup=bs(html, \"html.parser\")\n",
    "        downloads = soup.find(\"div\", class_=\"downloads\")\n",
    "        image_url = downloads.find(\"a\")[\"href\"]\n",
    "        dictionary = {\"title\": title, \"img_url\": image_url}\n",
    "        mars_hemisphere.append(dictionary)\n",
    "    return mars_hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function called scrape that will execute all of your scraping code from python script\n",
    "# and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "def scrape():\n",
    "    final_data = {}\n",
    "    output = marsNews()\n",
    "    final_data[\"mars_news\"] = output[0]\n",
    "    final_data[\"mars_paragraph\"] = output[1]\n",
    "    final_data[\"mars_image\"] = marsImage()\n",
    "    final_data[\"mars_facts\"] = marsFacts()\n",
    "    final_data[\"mars_hemisphere\"] = marsHem()\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
